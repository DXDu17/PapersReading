# An Overview Of 3D Object Detection

------

原文链接：[点这里](https://arxiv.org/abs/2010.15614)

## 目录

- [1. 摘要](#1)
- [2. 引言](#2)
- [3. 数据格式](#3)
  - [3.1 数据集](#3.1)
  - [3.2 预处理](#3.2)
- [4. 2D目标检测](#4)
- [5. 3D目标检测](#5)

<a name="1"></a>

## 1. 摘要

点云3D目标检测近年来受到广泛关注，成为3D计算机视觉领域的一个研究热点。然而由于点云的复杂性，在激光雷达(Lidar)（光探测和测距）中识别3D物体仍然是一个挑战。行人、骑行者或交通锥等目标通常由非常稀疏的点表示，仅使用点云使得检测非常复杂。此项目提出一种使用RGB和点云数据来做多类目标识别的框架。使用现有的2D检测模型在RGB图像上定位感兴趣区域（ROI），其次在点云中采用像素映射策略，将初始2D边界框扩散到3D空间。使用最近发布的nuScenes数据集（一个包含多种数据格式的大规模数据集）来训练和评估所提结构。

<a name="2"></a>

## 2. 引言

目标检测的任务是找到图像中的所有感兴趣区域（ROI），并确定它们的位置和类别。由于物体有不同的外观、形状和姿态，以及成像过程中受光照、遮挡等因素的干扰，目标检测一直是个具有挑战性的问题。

<a name="3"></a>

## 3. 数据格式

<a name="3.1"></a>

### 3.1 数据集

深度图是一种图像或图像通道，其中包含了场景中目标表面与视点之间的距离信息。深度图类似于灰度图，只是每个像素是传感器和目标之间的实际距离。一般来说，RGB图像和深度图像之间存在一对一的对应关系。RGB-D格式的数据集包括Pascal VOC、COCO、ImageNet等。

雷达数据在目标检测问题中也很有用。雷达数据是通过向物体表面发射无线电波收集的，然后利用反射信息计算目标的速度和到目标的距离。然而单靠雷达无法为检测和分类提供足够的信息，这就是为什么不同类型数据融合非常重要。

点云数据是指三维坐标系中的一组矢量，通常由X、Y和Z三维坐标表示，用于表征目标的外表面形状。每个点云还可以包含RGB颜色像素、灰度值、深度和法线这些信息。大多数点云数据由3D扫描设备生成，如激光雷达（2D/3D）、立体相机和TOF相机。这些设备自动测量目标表面大量的点信息，然后由.LAS或.LAZ文件保存。除了点云数据外还有与其对应的RGB图像，此类数据集包括KITTI、nuScenes、Waymo Open等。

本文使用nuScenes数据集来训练和评估模型。nuTonomy的nuScenes数据集是一个具有3D目标注释的大型自动驾驶数据集。与许多其他数据集相比，nuScenes数据集不仅具有更大的规模和更多的注释，而且还提供了整个传感器套件，包括激光雷达、雷达、GPS和IMU。下图是nuScenes的激光雷达点云示例。

<div align=center><img src="../images/An_Overview_Of_3D_Object_Detection/LIDAR point cloud.png" width="588" height="450"/></div>

<a name="3.2"></a>

### 3.2 预处理

数据集中的图像质量较高，但实际中天气等因素可能会影响图像质量，从而降低检测精度。一些交通场景去雾算法可以解决这类问题：

1）一种基于伽马校正和引导滤波的除雾方法，除雾前对图像进行伽马校正，然后对校正后图像进行三种不同比例的引导滤波处理。滤波图像由Retinex模型修正，再利用加权融合得到除雾结果。该方法得到的除雾图像具有较高的对比度和色彩一致性。

2）一种基于最大模糊相关图割的传输估计算法，解决雾浓度分布不均匀的问题。根据波长和雾浓度之间的相关性，建立适合交通监控图像的波相关物理成像模型。然后，根据波长与颜色之间的相关性提出算法。

<a name="4"></a>

## 4. 2D目标检测

### 



<a name="5"></a>

## 5. 3D目标检测

