# Single-Shot 3D Detection of Vehicles from Monocular RGB Images via Geometry Constrained Keypoints in Real-Time

------

原文链接：[点这里](https://arxiv.org/abs/2006.13084v1)

## 目录

- [1. 摘要](#1)
- [2. 引言](#2)
- [3. 相关工作](#3)
  - [3.1 基于3D先验边界框生成或损失](#3.1)
  - [3.2 基于几何推理与形状重建](#3.2)
  - [3.3 基于输入数据或特征表示转换](#3.3)
- [4. 实验](#4)

<a name="1"></a>

## 1. 摘要

提出一种新的3D单目目标检测方法，用于检测单目RGB图像中的车辆。通过预测额外的回归和分类参数将2D检测扩展到3D空间，从而使运行时间接近纯2D目标检测。在几何约束下附加参数转换为网络内的3D边界框关键点。所提方法具有完整的3D描述，包括三个旋转角度，因为是聚焦于图像平面内的某些关键点，所以可以通过无监督方式获取目标的方向。所提方法可以与任何目前的目标检测框架结合，只需很少的计算开销，并举例说明在SSD上如何预测3D边界框。在不同的自动驾驶数据集上测试了该方法；使用KITTI 3D目标检测基准和nuScenes目标检测基准对其进行了评估，都取得了有竞争力的结果。在所有测试数据集和图像分辨率方面都优于SOTA方法，速度超过20 FPS。

<a name="2"></a>

## 2. 引言

目标检测（2D/3D）是自动驾驶系统的关键，正在开发的自动驾驶汽车和配有先进驾驶辅助系统的消费级汽车都配备了一套传感器，如RGB相机、激光雷达、雷达等系统。激光雷达传感器测距精确，出框稳定，但是成本高。RGB图像提供了丰富的语义信息，但缺乏深度信息。因此，神经网络需要从单目RGB图像精确估计深度，并且要保证算法的实时性。

提出3D-GCK方法，能预测包含三个旋转角的完整3D边界框描述。只关注图像平面中的关键点，利用投影特性生成3D方向信息，因此不需要gt带有旋转角度信息。

使用一个标准的2D目标检测框架，添加所述扩展，将预测所得2D边界框扩展到3D空间。从2D到3D可以用最小的计算开销完成，实现实时性能。

总结贡献：

1）可以用SOTA 2D目标检测框架，将检测所得2D边界框扩展到3D；

2）用SSD举例说明所提3D-GCK框架的实用性；

3）在4种自动驾驶数据集上测试3D-GCK，KITTI、nuScenes、A2D2、Synscapes。

在nuScenes上的测试结果如下：

<div align=center><img src="../images/3D-GCK/result_in_nuscenes.png" width="550" height="300"/></div>

<a name="3"></a>

## 3. 相关工作

三种单目3D目标检测方法：

1）基于3D先验边界框生成或损失；

2）基于几何推理与形状重建；

3）基于输入数据或特征表示转换。

<a name="3.1"></a>

### 3.1 基于3D先验边界框生成或损失



<a name="3.2"></a>

### 3.2 基于几何推理与形状重建



<a name="3.3"></a>

### 3.3 基于输入数据或特征表示转换





<a name="4"></a>

## 4. 实验





