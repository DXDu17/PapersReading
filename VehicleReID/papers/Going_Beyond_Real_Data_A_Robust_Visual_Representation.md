# Going Beyond Real Data: A Robust Visual Representation for Vehicle Re-identification

------

原文链接：[点这里](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w35/Zheng_Going_Beyond_Real_Data_A_Robust_Visual_Representation_for_Vehicle_CVPRW_2020_paper.pdf)

## 目录

- [1. 摘要](#1)
- [2. 介绍](#2)
- [3. 相关工作](#3)
- [4. 方法](#4)
  - [4.1 合成数据](#4.1)
  - [4.2 表示学习](#4.2)
  - [4.3 后处理](#4.3)
- [5. 实验](#5)
  - [5.1 数据分析](#5.1)
  - [5.2 定量结果](#5.2)
  - [5.3 定性结果](#5.3)
- [6. 总结](#6)

<a name="1"></a>

## 1. 摘要

专注于真实场景开发一个鲁棒性的车辆reid系统。充分利用合成数据的优点，同时配备真实图像，为不同的视点和光照条件下的车辆学习一个鲁棒性的表示。通过对各种数据增强方法和常用的强基线的综合调查和评价，分析了制约车辆重识别性能的瓶颈。基于分析，设计了一种具有更好的数据增强、训练和后处理策略的车辆reid方法。所提方法在41个团队中获得了第1名，在私有测试集上有84.13%的mAP。

<a name="2"></a>

## 2. 介绍

智能交通系统(ITS)可以应用于现代城市中的现实问题。如通过估计交通流特性和自适应调整交通灯来优化交通设计，最大化交通能力。此外还提供了道路和周围环境的全面信息，通过检测车辆和行人，以及估计他们的运动，为自动驾驶系统生成驾驶政策。

ITS感知系统通常包括以下功能，检测交通要素，跟踪要素，计算交叉路口的车辆总数以及估计车辆姿态。车辆reid是ITS中最关键的组件之一，可以在不同时间甚至是在不同相机捕获的帧中查找同一车辆。

传统的reid方法首先在帧中独立检测目标，然后进行特征提取，总结出感兴趣目标的外观特征。由于图像中存在遮挡、噪声检测、不同光照条件和视点变化等问题，鲁棒的外观特征提取方法非常需要在不同的帧中表示相同的目标。有些方法使用目标的统计特征，如颜色直方图或梯度直方图（HOG）来提高特征表示的鲁棒性。然而，在许多具有挑战性的情况下，手工制作的统计特征不能表示在不同的视图和光照条件下或有遮挡的目标。

基于深度神经网络的reid方法已经证明优于传统的reid方法。一般来说，大多数都是由一个孪生(Siamese)网络和一个度量学习目标训练而成，如三元组损失（triplet loss），N-pair损失（N-pair loss）和角损失（angulate loss）。具体来说，这些目标旨在最小化来自同一辆车的特征表示之间的距离，同时区分不同车辆的特征表示。利用车辆类型、颜色和车辆姿态等额外信息设计reid网络结构可以进一步提高识别性能。还引入了各种图像生成方法来提高reid系统的性能。例如，引入域随机化，通过绘制具有指定姿态和颜色的车辆三维模型来生成图像。在文39中，GAN被证明是为reid系统生成训练数据的一种有效方法。

本文在真实场景中设计一个高精度的车辆reid系统。要解决三个主要问题：1）如何有效、高效地设计车辆reid网络；2）如何结合特定任务的信息进一步提高测试过程中的检索性能；3）给定多个reid网络，如何进一步提高reid性能。

<a name="3"></a>

## 3. 相关工作

车辆reid的最新进展主要得益于CNN学习的视觉深度表示。文13表示该领域已经提出有效的损失函数、采样策略等训练技术。例如，Liu等人将CNN特征与传统手工制作的特征融合，产生鲁棒的视觉表示。为了挖掘细粒度模式，Wang等人首先对车辆图像的关键点进行标注，挖掘基于部件的车辆特征。Shen等人利用车辆通常在短时间内会在相机下重新出现的先验知识，利用时空约束去除难负样本。

同时，车辆reid方法还利用了其他相关任务的经验，即行人reid和人脸识别，例如center loss，空间变换器和batch normalization neck。然而，现实中的车辆reid仍然是一项具有挑战性的任务，因为不同的相机、车辆方向、光照和遮挡会导致视觉外观发生较大的变化。

为了减少变异和学习鲁棒性的车辆表示，许多最近的工作已经探索了数据生成方法。如游戏引擎，证明合成数据用于训练reid网络是有效的。Zhou等人提出针对方向变化问题变换单视图特征来合成多视图特征，而Yao等人利用图形引擎来增广不同方向和属性的真实数据集。

最近，生成对抗网络（GAN）被广泛用于数据生成，不仅可以将图像样本的风格从源域转移到目标域，还可以生成具有特定属性的样本。本文探索了不同的数据增强方法，并允许模型”看到“更多的车辆变体，从而产生鲁棒性的视觉表示。

<a name="4"></a>

## 4. 方法

首先探讨数据生成方法，然后进行表示学习。在推理过程中，从训练好的模型中提取出视觉表示，并执行后处理方法。

<a name="4.1"></a>

### 4.1 合成数据

##### 风格转换

与经典的车辆reid数据不同，AICity-Flow由真实数据和合成数据组成。虽然合成数据中的id来自于真实世界，但合成图像与真实图像仍然存在明显的风格差异，即众所周知的域差距。为了解决这一问题，本文采用图像转换技术。像CycleGAN一样的框架，即UNIT，使用真实数据和合成数据作为两个不同的来源进行训练。在训练时输入图像需要在两个源之间转换。训练后将所有合成图像按照合成→真实方向进行转换，得到更加真实的样本，减小分布差距。

<div align=center><img src="../images/Going_Beyond_Real_Data_A_Robust_Visual_Representation/StyleTransform.png" width="900" height="372"/></div>

##### 内容操作

上面提到的样式转换方法不会改变图像内容。生成的数据在视觉外观上仍然接近原始输入，这可能限制了对合成数据的学习。为此还尝试通过内容操作生成新数据。DGNet是一种新颖的框架，可以生成具有不同视觉外观的样本，对reid任务特别有效。使用两个编码器分别负责外观和结构信息，而解码器根据外观和结构特征生成图像。在本文中，DG-Net在AICity Challenge提供的车辆reid数据集上进行训练。然后利用训练好的模型生成新的id。给定两种不同颜色的id图像，DG-Net将生成具有目标外观的新图像。为了避免由于相似的id引起的歧义以及由于低分辨率图像导致失败案例，在高分辨率子集上生成数据集。此外，为了使生成的数据具有一致的外观，只选择一个目标图像，为整个源图像提供外观嵌入。生成的数据只在微调阶段使用。

##### 复制和粘贴

还探索了直接的方法增广训练数据， 如复制粘贴，让模型“看到”更多的背景变量。将真实图像的前景与合成图像的背景相结合来生成新样本。 通过实例分割方法从真实图像中分割出前景车辆。应用DeepFill v2在去除前景的空白区域进行背景图像修复。 应用无缝图像克隆来融合前景和背景图像。

<a name="4.2"></a>

### 4.2 表示学习

##### 网络结构

根据现有的re-id工作，把在ImageNet上预先训练的SOTA网络作为骨干模块，包括ResNeXt101、ResNeXt101_32x8l_wsl和ResNet50_IBN_a。部署开源网络结构变体有：

vanilla reid基线将ImageNet的原始分类层替换为一个新的分类器模块。新的分类器模块包含一个全连接层fc1、一个BN层和一个全连接层fc2。fc1层将学习到的特征压缩到512维，fc2层作为线性分类器来输出类别预测。在推理时，提取fc2层之前的512维特征作为视觉表示。

另一个复杂的reid网络体系结构，融合了多尺度信息以增强车辆表示。下图简要说明了该网络结构。

<div align=center><img src="../images/Going_Beyond_Real_Data_A_Robust_Visual_Representation/network_architecture.png" width="652" height="268"/></div>

采用ResNet主干的最后两个块（即块3和块4）的激活。将这两个特征分别表示为X3和X4。全局平均池化（GAP）和全局最大池化（GMP）用于获得全局表示。在X4上执行输出大小为2×2的自适应平均池化（AAP）和自适应最大池化（AMP），以获得局部表示。X3_g_avg表示X3的全局平均池化特征，X4_a_max表示X4的自适应最大池化特征。同样还获得了X3_g_max、X4_g_avg、X4_g_max和X4_a_avg。所有上述输出特征都受到ranking loss的监督，以拉近相同id的样本，区分不同id的样本。X3_g_avg和X3 g_max被进一步送至head模块，X4_g_avg和X4_g_max、X4_a_avg和X4_a_avg也被送至head模块。head模块：BN1+leaky-relu+Conv+BN2+fc，用于预测车辆身份。交叉熵损失用于惩罚错误预测。

##### 优化函数



<a name="4.3"></a>

### 4.3 后处理





<a name="5"></a>

## 5. 实验







<a name="6"></a>

## 6. 总结



