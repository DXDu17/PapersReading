# DeepPose: Human Pose Estimation via Deep Neural Networks

------

原文链接：[点这里](https://arxiv.org/abs/1312.4659)

## 目录

- [1. 摘要](#1)
- [2. 介绍](#2)
- [3. 相关工作](#3)
- [4. 姿态估计深度学习模型](#4)
  - [4.1 基于DNN的姿态估计回归](#4.1)
  - [4.2 姿态回归器级联](#4.2)
- [5. 实验验证](#5)
  - [5.1 配置](#5.1)
  - [5.2 结果和讨论](#5.2)
- [6. 结论](#6)

<a name="1"></a>

## 1. 摘要

基于DNN提出一种人体姿态估计方法。姿态估计问题被视为基于DNN的人体关节回归问题。本文提出一个级联DNN回归器，可以得到高精度的姿态估计。该方法的优点是以一种整体的方式对姿态进行推理，利用深度学习的最新进展，在四个学术基准上进行了详细的实证分析。

<a name="2"></a>

## 2. 介绍

人体姿态估计问题，即人体关节定位问题，在计算机视觉领域受到了广泛关注。这个问题面临一些挑战：strong articulations、小到几乎看不见的关节、遮挡以及捕捉上下文。

主流工作主要受第一个挑战的推动，即需要在大型空间中搜索所有可能的关节姿态。近年来已经提出各种基于部位的模型。

要实现上述有效性，就需要牺牲一些表达能力：对单个部位进行推理，对身体各部位之间所有交互的一小部分进行建模。虽然已经有方法来解决这种局限性，并提出用整体方式做推理，但不能成功的解决实际问题。

本文利用深度学习的最新进展，提出一种基于DNN的新算法。DNN在视觉分类任务和目标定位方面表现出出色的性能，但在精确定位关节位置方面有所欠缺。本文就人体姿态问题，提出一种简单强大的方法。

将姿态估计表述为关节回归问题，并展示如何设计DNN网络。使用完整图像作为输入，加上一个7层通用卷积神经网络，来回归每个身体关节位置。这个构想有两个优点：1）DNN能够捕捉每个身体关节的完整背景；2）无需为部位设计特征表示和检测器，无需显式设计模型拓扑结构及关节之间的交互。本文证明一个通用卷积神经网络可以学习这个回归问题。

此外，本文提出一个基于DNN的级联姿态预测器。这样的级联可以提高关节定位的精度。从初始姿态估计开始，使用更高分辨率的子图像来细化关节预测。

最后在四个广泛使用的基准上展示了SOTA结果，并通过跨数据集评估展示泛化性能。

<a name="3"></a>

## 3. 相关工作

计算机视觉早期就提出使用部位图形化表示关节目标，尤其是人体姿态方面。Fishler和Elschlager提出图像约束（Pictorial Stricture, PSs），Felzenszwalb和Huttenlocher利用距离变换技巧优化了这个方法，使其易于处理。由此随后开发出各种基于PS的模型。

由于包含一个基于树结构的简单二元姿态模型（此模型不依赖于图像数据），上述可处理性就受到了限制。目前的研究在保持可处理性的同时，集中于使模型具有更丰富的表达能力。早期的尝试是丰富部位检测器。近期提出的模型注重表达复杂的关节关系。Yang和Ramanan使用部位混合模型。Johnson和Everingham研究了全模型尺寸的混合模型，即PSs混合模型。Tian等人在分层模型中捕捉到了更丰富的高阶空间关系。另一种方法是通过图像依赖PS模型获取高阶关系，该模型可以通过全局分类器进行估计。

以上方法的实用性有限。Mori和Malik试图从一组标记图像中为每个测试图像找到最接近的样本，并迁移关节位置。Shakhnarovich等人也采用了类似的最近邻设置，但他们使用了局部敏感哈希(LSH)。最近，Gkioxari等人提出一种用于部位配置的半全局分类器。这个公式在真实数据上显示了非常好的结果，然而它是基于线性分类器，表达能力不如本文方法，并且仅在胳膊样本上测试。Ionescu等人采用姿态回归的思想，但他们仅针对3D姿态做推理。

与本文最接近的工作是使用CNN和邻域分量分析来回归姿态点，但这项工作没有采用级联网络。DNN级联回归器还仅用在面部点的定位任务中。

<a name="4"></a>

## 4. 姿态估计深度学习模型

本文使用以下符号。为了表示姿态，定义姿态向量为y=(..., yTi, ...)T, i ∈ {1, . . . , k}对所有k个身体关节的位置进行编码，其中yi包含第i个关节的x和y坐标。标注过的图像由(x, y)表示，其中x代表图像数据，y是gt姿态向量。

对于关节坐标在绝对图像中的位置，用包围人体或部位的bbox对其进行归一化。一般情况下该bbox表示完整图像。box由其中心bc、bw和高度bh定义。关节yi通过box中心平移，并通过box大小缩放，我们称之为box的归一化。

本文对姿态向量元素应用相同的归一化方式生成姿态向量。使用N(x;b)来表示图像x的裁剪。为了简洁起见，我们用b表示N(·)归一化，作为完整的图像框。

<a name="4.1"></a>

### 4.1 基于DNN的姿态估计回归

本文将姿态估计视为回归问题，训练并使用函数ψ(x;θ)，为图像x回归出一个归一化的姿态向量，其中θ表示模型的参数。使用公式(1)中的归一化变换，姿态预测y∗在绝对图像坐标中表示为

尽管公式简单，但该方法的能力和复杂度在于ψ，它基于卷积深度神经网络。这种卷积网络由几层组成——每层都是一个线性变换后跟一个非线性变换。第一层接收网络输入数据，最后一层输出回归的目标值，在本文中是2k关节坐标。

本文将ψ的结构建立在Krizhevsky等人在图像分类方面的工作基础上，其在目标定位方面也显示了出色的结果。本文网络由7层组成，C表示卷积层，LRN表示局部响应归一化层，P表示池化层，F表示全连接层。只有C层和F层包含可学习的参数，而其余层没有参数。本文的C层和F层由一个线性变换后跟一个非线性变换，线性变换是修正线性单元。

使用DNN结构是基于其在分类和定位问题上的杰出成果。在实验部分，本文展示了这样一个通用框架可以用于学习一个模型，从而在姿态估计方面达到SOTA水平。此外，这种模型是一个真正的整体模型——最终的关节位置估计是基于完整图像的复杂非线性变换。

此外，使用DNN可以避免设计针对特定域的姿态模型，模型和特征是从数据中学习的。尽管回归损失不会对关节之间的显式交互进行建模，但所有7个隐藏层都会隐式捕捉到这种交互——所有关节回归器都共享所有内部特征。

训练：差值就是损失。与分类损失不同，在最后一个网络层上训练线性回归，通过最小化预测和gt姿态向量之间的L2距离来预测姿态向量。由于gt姿态向量是在绝对图像坐标中定义的，并且姿态尺寸随图像而异，因此我们使用公式(1)来归一化训练集D。然后计算L2损失以获得最优网络参数。

本文写下各个关节的优化。对于某些图像，并非所有关节都做了标注，但可以使用上述目标，忽略总和中的相应项即可。

采用反向传播分布在线执行参数θ优化。对于大小为128的mini-batch，计算自适应梯度更新。学习率设置为0.0005。由于该模型有大量参数，且使用的数据集相对较小，使用大量随机操作裁剪、左/右翻转做数据增强，并将F层设置为0.6来做DropOut正则化。

<a name="4.2"></a>

### 4.2 姿态回归器级联

上一节姿态公式的优点是基于完整图像进行关节估计，并且依赖上下文。但由于输入尺寸固定为220×220，网络对细节的处理能力有限——学习的感受野只能在粗略尺度上捕获姿态特性。粗略估计不能精确定位身体关节。不能简单的增加输入大小，这会增加参数量。为获得更好的精度，建议训练一个级联的姿态回归器。第一阶段，级联从估算初始姿态开始。随后阶段训练额外的DNN回归器，来预测关节位置在第一阶段中与gt之间的偏移。因此，每个后续阶段可以被认为是对当前预测的细化。

每个后续阶段使用预测的关节位置来聚焦图像的相关部分——子图像基于前一阶段预测的关节位置进行裁剪，并在该子图像上应用该关节的姿态位移回归。通过这种方式，后续的姿态回归器可以看到更高分辨率的图像，从而学习更精细尺度的特征，最终获得更高的精度。

本文对级联的所有阶段使用相同的网络架构，但学习不同的网络参数。对于S级联阶段的某个阶段s∈ {1, …, S}，用θs表示学习的网络参数。因此姿态位移回归器读作ψ(x: θs)。为了细化给定的关节位置yi，考虑在yi周围用一个关节包围框bi捕获一个子图像: bi(y: Sigi)＝(yi,  σdiam(y), σdiam(y))，该子图像以第i个关节为中心，并以由σ缩放的姿态直径为尺度。姿态直径diam(y)定义为人体躯干上相对关节之间的距离，如左肩和右髋取决于具体的姿态定义和数据集。

使用上述符号，在阶段s=1，本文从边界框b0开始，b0包含完整图像或者由一个人体检测器获得。由此获得一个初始姿态：
在随后s≥2的每个阶段，对于所有关节i∈{1, ..., k}，首先通过由前一阶段(s-1)上获得的b定义子图像，在子图像上应用回归器，回归出一个细化的位移。然后估计一个新的关节框：

本文将级联数固定为S，其根据章节4.1的解释定义。

训练：网络参数θ1由章节3.1概述的公式(4)训练得到。在s≥2的每个阶段，除了有一个地方是不同的之外，其他训练过程是相同的。使用不同的bbox对训练样本(x, y)中的每个关节i进行归一化——他以前一阶段获得的同一关节的预测为中心——因此是在前一阶段模型的基础上对该阶段的训练进行了调整。

由于深度学习方法具有较强的能力，本文通过对每个图像和关节使用多次归一化来增强训练数据。不是只使用前一阶段的预测，而是生成一个模拟预测。这是通过用二维正态分布N随机采样得到的向量随机替换关节i的gt位置，正态分布的均值和方差等于观测位移的均值和方差，观测位移从所有训练数据获得。首先从原始数据中均匀的采样一个样本和一个关节，然后基于从N(s)中采样的位移δ生成一个模拟预测，可以定义完整的增强训练数据。

级联阶段s的训练目标如公式(4)所示，特别注意对每个关节使用正确的归一化：

<a name="5"></a>

## 5. 实验验证

<a name="5.1"></a>

### 5.1 配置

数据

人体姿态估计有许多基准。本文使用具有大量训练样本的数据集，足够训练一个DNN大模型，具有现实意义和挑战性。

使用的第一个数据集是FLIC，从好莱坞电影中获得，由4000个训练图像和1000个测试图像组成。形象和姿态多种多样。每个被标记的人身上有10个上身关节点。

使用的第二个数据集是LSD及其扩展。本文将其与LSP合并。包含11000个训练图像和1000个测试图像，都是体育活动中的图像，大多数人有150像素的高度，非常具有挑战性。每个人全身标注有14个关节点。

对于上述所有数据集，本文将姿态y的直径定义为相对侧肩部和臀部之间的距离，并用diam(y)表示。所有数据集的关节都以树形排列，来模拟人体。肢体定义为姿态树中一对相邻关节的连接。



指标

为了能够与公开结果比较，本文将使用两个广泛接受的评估指标。PCP(Percentage of Correct Parts)测量肢体的检测率，如果两个预测关节位置和真实肢体关节位置之间的距离最多为肢体长度的一半，则认为肢体被检测到。PCP最初是首选的评估指标，但它的缺点是会惩罚较短的肢体，如下肢，这些肢体通常很难检测。

为了解决这一缺点，近期研究使用不同的检测标准展示关节的检测率——如果预测关节和真实关节之间的距离在躯干直径的某个范围内，则认为检测到了关节。通过改变这个范围，可以获得不同定位精度下的检测率。该度量减轻了PCP的缺点，因为所有关节的检测标准都基于相同的距离阈值。该指标称为PDJ(ercent of Detected Joint)。



实验细节

所有实验使用相同的网络结构。受文7的启发，在FLIC上使用了一个人体检测器，初步获得粗略的人体边界框。它基于人脸检测器——检测到的人脸矩形由固定的缩放器放大。此缩放器是根据训练数据确定的，因此得到的人体边界框会包含所有标记的关节。这种基于人脸的身体检测器会产生一个粗略的估计，为本文方法提供了一个良好的起点。对于LSP，则使用完整的图像作为初始边界框，因为这个数据中的人体裁剪相对紧密。

从本文所述两个数据集中选出一组50张图像来确定算法超参数。为了测量参数的最优性，在所有关节上使用了0.2的PDJ平均值。缩放器σ将细化关节边界框的尺寸定义为姿态尺寸的一部分，其确定如下：尝试{0.8,1.0,1.2}后，FLIC选择σ=1.0；尝试{1.5,1.7,2.0,2.3}后，LSP选择σ=2.0。级联阶段S的值由训练阶段决定，直到算法在所选数据集上的效果不再提高。对于FLIC和LSP，S=3。

为了提高泛化能力，从s=2开始的每个级联阶段，对每个关节进行40次随机转换剪裁采样。对于具有14个关节的LSP，在镜像和采样后，训练样本的数量为11000×40×2×14=12M。

所提算法能够复现。在12核CPU上，每张图像的运行时间约为0.1s。文19运行时间大约为4s，文26运行时间大约是1.5s。方法和训练过程都很复杂。初始阶段用100 worker训练3天，最终效果要到12小时后完成。当使用数据增强后，数据是原始数据的40倍时，每个细化阶段要训练7天。

<a name="5.2"></a>

### 5.2 结果和讨论

**对比**    给出与其他方法的比较结果。本文在LSP上使用图1中的PCP指标做比较。展示了四个最具挑战性的肢体结果——上臂和下肢——以及所有对比算法检测出的这些肢体的平均值。本文方法表现明显优于所有其他方法，尤其是对腿部有更好的估计。大腿准确度从0.74提高到0.78。虽然其他方法在特定肢体上表现出优势，但DeepPose对所有具有挑战性的肢体都有很好的效果。

PDJ指标允许改变预测和gt之间距离的阈值。这个阈值被认为是一个定位精度，在此精度下检测率能被绘制出来。因此可以在不同精度下比较这些方法。图3和图4分别展示了在FLIC和LSP上的结果，并与另外四种方法进行了比较。对于每个数据集，根据每个数据集的规则进行训练和测试。与之前的实验类似，本文算法性能在五种算法中是最优的。在低精度域中，本文方法的增益更大，虽然不能精确定位关节位置，但是可以检测出粗略的姿态。在FLIC上，当归一化距离为0.2时，肘部和手腕的检测率比第二名分别高0.15和0.2。在LSP上，当归一化距离为0.5时，检测率提高了0.1。在LSP低精度范围内，当归一化距离为0.2时，本文在腿部和难以检测的手臂上表现出了类似的性能。实现这样的效果归因于DNN方法使用7层网络转换来计算关节坐标，网络中包含了max pooling层。

本文方法在电影场景和运动场景中都有较好的检测结果。



**级联细化效果**    单层DNN关节回归器只能粗略定位关节位置。想要获取更精确的位置，后续级联细化过程更重要。从图5可以看出，细化过程效果提升比较明显的位置是在[0.15, 0.2]归一化距离之间。提升效果的操作是第一阶段之后的细化过程。因为后续阶段使用的图像是经前一阶段获取的子图像，虽然输入图像的分辨率更高，但是背景信息很有限。

图6是经过细化之后，与gt对比的结果图像。初始阶段通常能估计出大致的姿态，但是并不能捕获正确的位置。例如图6第3行，虽然姿态正确，但是比例不对。第2行的预测结果比gt结果有所偏移。大多数情况下，级联第二阶段可以解决关节对不齐问题。特殊情况下，如第1行，增加阶段会提高单个关节定位的精确度。

**跨数据集泛化**    为了验证算法的泛化性能，在LSP和FLIC两个相关的数据集上验证。模型在LSP上训练，在Image Parse dataset上测试。Image Parse dataset数据与LSP类似，包含了运动人体数据，但是其中许多图片来自个人拍摄，并且包含其他动作。此外，在FLIC上训练的上半身模型在全部Buffy dataset上测试。与其他方法相比，本文方法可以保持SOTA性能，显示了良好的泛化能力。

**示例姿态**    本文算法在LSP图像上的姿态估计可视化如图8所示，能在不同条件下获得大多数关节的正确姿态。当姿态估计精度不高时，仍然能保持一个正确的外形。常见的错误是左侧和右侧容易混淆。在FLIC上的结果更好一些，偶尔出现下臂估计错误。

<a name="6"></a>

## 6. 结论

本文首次将DNN应用于人体姿态估计。将人体姿态估计问题表述为基于DNN的关节坐标回归问题，所提级联回归器的优点是以整体方式捕获上下文并对姿态进行推理。并在几个具有挑战性的学术数据集上取得SOTA结果。

为分类任务设计的通用分类CNN可以应用于不同的定位任务，未来将研究新的架构，更好的解决定位问题。
