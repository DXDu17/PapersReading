# DeepPose: Human Pose Estimation via Deep Neural Networks

------

原文链接：[点这里](https://arxiv.org/abs/1312.4659)

## 目录

- [1. 摘要](#1)
- [2. 介绍](#2)
- [3. 相关工作](#3)
- [4. 姿态估计深度学习模型](#4)
  - [4.1 基于DNN的姿态估计回归](#4.1)
  - [4.2 姿态回归器级联](#4.2)
- [5. 实验验证](#5)
  - [5.1 配置](#5.1)
  - [5.2 结果和讨论](#5.2)
- [6. 结论](#6)

<a name="1"></a>

## 1. 摘要

基于DNNs提出一种人体姿态估计方法。姿态估计是一个基于DNN的人体关节回归问题。提出一个级联DNN回归器，可以得到高精度的姿态估计。该方法的优点是以一种整体的方式对姿态进行推理，并且有一个简单但强大的公式，利用深度学习的最新进展，针对不同现实世界图像的四个学术基准展示了详细的实证分析。

<a name="2"></a>

## 2. 介绍

人体姿态估计问题，即人体关节的定位问题，在计算机视觉领域受到了广泛的关注。这个问题的一些挑战——强关节、小到几乎看不见的关节、遮挡以及捕捉上下文的需要。

这一领域的主流工作主要受到第一个挑战的推动，即需要在大空间中搜索所有可能的关节姿态。基于部位的模型自然适合于模型表达，近年来已经提出各种具有有效推理的模型。

然而，要达到上述效率需要以有限的表现力为代价——使用部位检测器，这在许多情况下是关于单个部位的，最重要的是通过对身体各部分之间所有交互的一小部分进行建模。这些局限性已经被认识到，并且已经提出以整体方式对姿态进行推理的方法，但在现实问题中的成功有限。

本文将其归因于人类姿态估计的整体观点。利用深度学习的最新发展，提出一种基于DNN的新算法。DNN在视觉分类任务和目标定位方面表现出出色的性能。然而应用DNN精确定位关节目标的问题在很大程度上仍未得到解答。本文试图阐明这个问题，并为DNN整体人体姿态估计提出一个简单而强大的公式。

将姿态估计表述为一个关节回归问题，并展示如何将其成功的放置在DNN设置中。使用完整图像作为输入和一个7层通用卷积DNN，来回归每个身体关节位置。这个构想有两个优点。首先，DNN能够捕捉每个身体关节的完整背景——每个关节回归器使用完整图像作为信号。其次，与基于图形模型的方法相比，该方法的制定要简单得多——无需为部位明确设计特征表示和检测器；无需显式设计模型拓扑结构及关节之间的交互。本文证明一个通用的卷积DNN可以学习这个问题。

此外，还提出一个基于DNN的级联姿态预测器。这样的级联可以提高关节定位的精度。从初始姿态估计开始，基于完整图像，学习基于DNN的回归器，通过使用更高分辨率的子图像来细化关节预测。

根据所有报告的结果，在四个广泛使用的基准上展示了SOTA结果或优于SOTA的结果。本文方法在人像上表现得很好，这些人在外表和关节上表现出强烈的差异。最后通过跨数据集评估展示泛化性能。

<a name="3"></a>

## 3. 相关工作

使用部位图形化表示关节目标，尤其是人体姿态的想法，从计算机视觉的早期就被提出。Fishler和Elschlager提出图像约束（Pictorial Stricture, PSs），Felzenszwalb和Huttenlocher利用距离变换技巧使其易于处理和实用。由此，随后开发出各种具有实际意义的基于PS的模型。

上述可处理性受到基于树结构的姿态模型的限制，该模型具有二元性，不依赖于图像数据。因此，在保持可处理性的同时，研究集中于丰富模型的表达能力。早期实现这一目标的尝试是基于更丰富的部位检测器。近期提出各种各样的模型来表达复杂的关节关系。Yang和Ramanan使用部位混合模型。Johnson和Everingham研究了全模型尺寸的混合模型，即PSs混合模型。Tian等人在分层模型中捕捉到了更丰富的高阶空间关系。另一种方法是通过图像依赖PS模型获取高阶关系，该模型可以通过全局分类器进行估计。

归因于在整体方式上的姿态推理哲学，这些方法的实用性有限。Mori和Malik试图从一组标记图像中为每个测试图像找到最接近的样本，并迁移关节位置。Shakhnarovich等人也采用了类似的最近邻设置，但他们使用了对位置敏感的哈希。最近，Gkioxari等人提出一种用于部位配置的半全局分类器。这个公式在真实数据上显示了非常好的结果，然而它基于线性分类器，表达能力不如本文，并且仅在arms上测试。最后，Ionescu等人采用姿态回归的思想，但他们仅对3D姿态进行了推理。

与本文最接近的工作是使用CNNs和邻域分量分析来回归出在嵌入表示姿态中的一个点。然而这项工作并没有采用级联网络，但是DNN回归器的级联已用于面部点的定位。

<a name="4"></a>

## 4. 姿态估计深度学习模型

本文使用以下符号。为了表达一个姿态，定义姿态向量为y=(..., yTi, ...)T, i ∈ {1, . . . , k}对所有k个身体关节的位置进行编码，其中yi包含第i个关节的x和y坐标。标注过的图像由(x, y)表示，其中x代表图像数据，y是gt姿态向量。

对于关节坐标在绝对图像中的位置，用包围人体或部位的bbox对其进行归一化是有益的。一般情况下该bbox表示完整图像。这样一个box由其中心bc、bw和高度bh定义。关节yi通过box中心平移，并通过box大小缩放，我们称之为box的化。

本文对姿态向量元素应用相同的归一化方式生成姿态向量。最后通过bbox使用N(x;b)来表示图像x的裁剪，这实际上通过bbox来归一化图像。为了简洁起见，我们用b表示N(·)归一化，作为完整的图像框。

<a name="4.1"></a>

### 4.1 基于DNN的姿态估计回归

本文将姿态估计视为回归问题，训练并使用函数ψ(x;θ)，为图像x回归出一个归一化的姿态向量，其中θ表示模型的参数。使用公式(1)中的归一化变换，姿态预测y∗在绝对图像坐标中表示为

尽管公式简单，但该方法的能力和复杂度在于ψ，它基于卷积深度神经网络。这种卷积网络由几层组成——每层都是一个线性变换后跟一个非线性变换。第一层接收网络输入数据，最后一层输出回归的目标值，在本文中是2k关节坐标。

本文将ψ的结构建立在Krizhevsky等人于图像分类方面的工作基础上，其在目标定位方面也显示了出色的结果。本文网络由7层组成，C表示卷积层，LRN表示局部响应归一化层，P表示池化层，F表示全连接层。只有C层和F层包含可学习的参数，而其余层没有参数。本文的C层和F层由一个线性变换后跟一个非线性变换，线性变换是修正线性单元。

使用DNN结构是基于其在分类和定位问题上的杰出成果。在实验部分，本文展示了这样一个通用框架可以用于学习一个模型，从而在姿态估计方面达到最先进的水平或更好的性能。此外，这种模型是一个真正的整体模型——最终的关节位置估计是基于完整图像的复杂非线性变换。

此外，使用DNN可以避免设计针对特定域的姿态模型，模型和特征是从数据中学习的。尽管回归损失不会对关节之间的显式交互建模，但所有7个隐藏层都会隐式捕捉到这种交互——所有关节回归器都共享所有内部特征。

训练：差值就是损失。与分类损失不同，在最后一个网络层上训练线性回归，通过最小化预测和gt姿态向量之间的L2距离来预测姿态向量。由于gt姿态向量是在绝对图像坐标中定义的，并且姿态尺寸随图像而异，因此我们使用公式(1)来归一化训练集D。然后计算L2损失以获得最优网络参数。

本文写下各个关节的优化。对于某些图像，并非所有关节都做了标注，但可以使用上述目标，忽略总和中的相应项即可。

采用反向传播分布在线执行参数θ优化。对于大小为128的mini-batch，计算自适应梯度更新。学习率设置为0.0005。由于该模型有大量参数，且使用的数据集相对较小，使用大量随机操作裁剪、左/右翻转做数据增强，并将F层设置为0.6来做DropOut正则化。

<a name="4.2"></a>

### 4.2 姿态回归器级联

上一节姿态公式的优点是基于完整图像的关节估计，并且依赖上下文。但由于输入尺寸固定为220×220，网络对细节的处理能力有限——学习的感受野只能在粗略尺度上捕获姿态特性。粗略估计不能精确定位身体关节。不能简单的增加输入大小，这会增加参数量。为获得更好的精度，建议训练一个级联的姿态回归器。第一阶段，级联从上一节估算初始姿态开始。随后阶段，训练额外的DNN回归器，来预测关节位置在第一阶段中与gt之间的偏移。因此，每个后续阶段可以被认为是对当前预测的细化。

每个后续阶段使用预测的关节位置来聚焦图像的相关部分——子图像基于前一阶段预测的关节位置进行裁剪，并在该子图像上应用该关节的姿态位移回归。通过这种方式，后续的姿态回归器可以看到更高分辨率的图像，从而学习更精细尺度的特征，最终获得更高的精度。

本文对级联的所有阶段使用相同的网络架构，但学习不同的网络参数。对于S级联阶段的某个阶段s∈ {1, …, S}，用θs表示学习的网络参数。因此姿态位移回归器读作ψ(x: θs)。为了细化给定的关节位置yi，考虑在yi周围用一个关节包围框bi捕获一个子图像: bi(y: Sigi)＝(yi,  σdiam(y), σdiam(y))，该子图像以第i个关节为中心，并以由σ缩放的姿态直径为尺度。姿态直径diam(y)定义为人体躯干上相对关节之间的距离，如左肩和右髋取决于具体的姿态定义和数据集。

使用上述符号，在阶段s=1，本文从边界框b0开始，b0包含完整图像或者由一个人体检测器获得。由此获得一个初始姿态：
在随后s≥2的每个阶段，对于所有关节i∈{1, ..., k}，首先通过由前一阶段(s-1)上获得的b定义子图像，在子图像上应用回归器，回归出一个细化的位移。然后估计一个新的关节框：

本文将级联数固定为S，其根据章节4.1的解释定义。

训练：网络参数θ1由章节3.1概述的公式(4)训练得到。在s≥2的每个阶段，除了有一个地方是不同的之外，其他训练过程是相同的。使用不同的bbox对训练样本(x, y)中的每个关节i进行归一化——他以前一阶段获得的同一关节的预测为中心——因此是在前一阶段模型的基础上对该阶段的训练进行了调整。

由于深度学习方法具有较大的能力，本文通过对每个图像和关节使用多次归一化来增强训练数据。不是只使用前一阶段的预测，而是生成一个模拟预测。这是通过用二维正态分布N随机采样得到的向量随机替换关节i的gt位置，正态分布的均值和方差等于观测位移的均值和方差，观测位移从所有训练数据获得。首先从原始数据中均匀的采样一个样本和一个关节，然后基于从N(s)中采样的位移δ生成一个模拟预测，可以定义完整的增强训练数据。

级联阶段s的训练目标如公式(4)所示，特别注意对每个关节使用正确的归一化：

<a name="5"></a>

## 5. 实验验证

<a name="5.1"></a>

### 5.1 配置

数据

人体姿态估计有许多基准。本文使用具有大量训练样本的数据集，足够训练一个DNN大模型，具有现实意义和挑战性。

使用的第一个数据集是FLIC，从好莱坞电影中获得，由4000个训练图像和1000个测试图像组成。形象和姿态多种多样。每个被标记的人身上10个上身关节点。

使用的第二个数据集是LSD及其扩展。本文将其与LSP合并。包含11000个训练图像和1000个测试图像，都是体育活动中的图像，大多数人有150像素的高度，非常具有挑战性。每个人全身标注有14个关节点。

对于上述所有数据集，本文将姿态y的直径定义为相对侧肩部和臀部之间的距离，并用diam(y)表示。所有数据集的关节都以树形排列，来模拟人体。肢体定义为姿态树中一对相邻关节的连接。



指标

为了能够与公开结果比较，本文将使用两个广泛接受的评估指标。PCP(Percentage of Correct Parts)测量肢体的检测率，如果两个预测关节位置和真实肢体关节位置之间的距离最多为肢体长度的一半，则认为肢体被检测到。PCP最初是首选的评估指标，但它的缺点是会惩罚较短的肢体，如下肢，这些肢体通常很难检测。

为了解决这一缺点，近期使用不同的检测标准展示关节的检测率——如果预测关节和真实关节之间的距离在躯干直径的某个分数内，则认为检测到了关节。通过改变这个分数，可以获得不同定位精度下的检测率。该度量减轻了PCP的缺点，因为所有关节的检测标准都基于相同的距离阈值。我们将该指标称为PDJ(ercent of Detected Joint)。



实验细节

所有实验使用相同的网络结构。受文7的启发，在FLIC上使用了一个人体检测器，初步获得人体边界框的粗略估计。它基于人脸检测器——检测到的人脸矩形由固定的缩放器放大。此缩放器是根据训练数据确定的，因此得到的人体边界框会包含所有标记的关节。这种基于人脸的身体检测器会产生一个粗略的估计，为本文方法提供了一个良好的起点。对于LSP，使用完整的图像作为初始边界框，因为数据中的人体裁剪相对紧密。

从本文所述两个数据集中选出一组50张图像来确定算法超参数。为了测量参数的最优性，在所有关节上使用了0.2的PDJ平均值。缩放器σ将细化关节边界框的尺寸定义为姿态尺寸的一部分，其确定如下：尝试{0.8,1.0,1.2}后，FLIC选择σ=1.0；尝试{1.5,1.7,2.0,2.3}后，LSP使用σ=2.0。级联阶段S的值由训练阶段决定，直到算法在所选数据集上的效果不再提高。对于FLIC和LSP，获得S=3。

为了提高泛化能力，从s=2开始的每个级联阶段，对每个关节进行40次随机转换剪裁采样。对于具有14个关节的LSP，在镜像图像和采样后，训练样本的数量为11000×40×2×14=12M。

所提算法能够复现。在12核CPU上，每张图像的运行时间约为0.1s。文19运行时间大约为4s，文26运行时间大约是1.5s。方法和训练过程都很复杂。初始阶段用100进程/线程训练3天，最终效果要到12小时后完成。当数据增强后，数据是原始数据的40倍时，每个细化阶段要训练7天。

<a name="5.2"></a>

### 5.2 结果和讨论

对比

给出与其他方法的比较结果。本文在LSP上使用图1中的PCP指标做比较。展示了四个最具挑战性的肢体结果——上臂和下肢——以及所有对比算法检测出的这些肢体的平均值。本文方法表现明显优于所有其他方法，尤其是对腿部由更好的估计。大腿准确度从0.74提高到0.78。虽然其他方法在特定肢体上表现出优势，但DeepPose对所有具有挑战性的肢体都有很好的效果。

PDJ指标允许改变预测和gt之间距离的阈值。这个阈值被认为是一个定位精度，在此精度下检测率能被绘制出来。因此可以在不同精度下比较这些方法。图3和图4分别展示了在FLIC和LSP上的结果，并与另外四种方法进行了比较。对于每个数据集，根据每个数据集的规则进行训练和测试。与之前的实验类似，本文算法性能在五种算法中是最优的。

<a name="6"></a>

## 6. 结论

