# Deep Learning-Based Human Pose Estimation: A Survey

------

原文链接：[点这里](https://arxiv.org/abs/2012.13392)

## 目录

- [1. 摘要](#1)
- [2. 介绍](#2)
- [3. 人体建模](#3)
  - [3.1 运动学模型](#3.1)
  - [3.2 平面模型](#3.2)
  - [3.3 体积模型](#3.3)
- [4. 2D人体姿态估计](#4)
  - [4.1 2D单人姿态估计](#4.1)
    - [4.1.1 回归方法](#4.1.1)
    - [4.1.2 身体部位检测方法](#4.1.2)
  - [4.2 2D多人姿态估计](#4.2)
    - [4.2.1 自顶向下方法](#4.2.1)
    - [4.2.2 自底向上方法](#4.2.2)
  - [4.3 2D HPE总结](#4.3)
- [5. 3D人体姿态估计](#5)
  - [5.1 基于单目RGB图像和视频的3D HPE](#5.1)
  - [5.2 其他来源的3D HPE](#5.2)
  - [5.3 3D HPE总结](#5.3)
- [6. 数据集和评价指标](#6)
  - [6.1 2D HPE数据集](#6.1)
  - [6.2 2D HPE评价指标](#6.2)
  - [6.3 2D HPE方法性能比较](#6.3)
  - [6.4 3D HPE数据集](#6.4)
  - [6.5 3D HPE评价指标](#6.5)
  - [6.6 3D HPE方法性能比较](#6.6)
- [7. 应用](#7)
- [8. 结论和未来方向](#8)

<a name="1"></a>

## 1. 摘要

人体姿态估计的目的是定位人体部位，并根据输入数据（如图像和视频）构建人体表示（如人体骨架）。其应用包括人机交互、运动分析、增强现实和虚拟现实。基于深度学习的人体姿态估计由于训练数据不足、深度模糊和遮挡而存在挑战。通过系统分析和比较，全面回顾基于深度学习的2D和3D姿势估计解决方案，还包括2D和3D人体姿态估计数据集和评价指标，性能比较。

<a name="2"></a>

## 2. 介绍

人体姿态估计（HPE）涉及从传感器捕获输入数据，特别是图像和视频，估计人体各部分的结构。HPE提供人体的几何和运动信息，已广泛应用于人机交互、运动分析、增强现实（AR）、虚拟现实（VR）、医疗保健等。此类方法已被证明在各种任务（包括图像分类、语义分割和目标检测）中优于经典的计算机视觉方法。遮挡、训练数据不足和深度模糊等对基于深度学习的HPE技术仍是需要克服的困难。基于深度学习的2D单人人体姿势估计已达到高性能，复杂场景中高度遮挡的多人HPE受到了广泛关注。对于3D HPE，获得精确的3D姿态标注比2D困难。运动捕捉系统可以在受控的实验室环境中采集3D姿态标注，但在自然环境中的应用有局限性。对于基于单目RGB图像和视频的3D HPE，主要挑战是深度模糊。在多视图设置中，视点关联是需要解决的关键问题。一些工程使用了诸如深度传感器、惯性测量单元（IMU）和射频设备等传感器，但这些方法通常不具有成本效益，并且需要专用硬件。

文11涵盖了带有RGB输入的3D HPE方法。文13回顾了2D HPE方法并分析了模型解释。文12总结了单目HPE从经典到基于深度学习的方法（到2019年），仅涵盖单目图像/视频中的2D HPE和3D单视图HPE。

综述分类如下：

<div align=center><img src="../images/Deep_Learning_Based_Human_Pose_Estimation_A_Survey/Taxonomy.png" width="813" height="166"/></div>

<a name="3"></a>

## 3. 人体建模

人体建模是HPE的一个重要方面。大多数HPE方法使用N关节刚体运动学模型。人体是具有关节和四肢的复杂实体，包含人体运动学结构和体形信息。在典型的方法中，使用基于模型的方法来描述和推断人体姿态，并渲染2D和3D姿态。人体建模通常有三种：运动学模型（用于2D/3D HPE）、平面模型（用于2D HPE）和体积模型（用于3D HPE）。

人体建模的三种类型如下：

<div align=center><img src="../images/Deep_Learning_Based_Human_Pose_Estimation_A_Survey/modeling.png" width="463" height="327"/></div>

<a name="3.1"></a>

### 3.1 运动学模型

运动学模型也称为基于骨架的模型或运动学链模型，包括一组关节位置和肢体方向，来表示人体结构，用于捕捉不同身体部位之间的关系。图形结构模型（PSM）是一种广泛使用的图形模型，也称为树结构模型。这种灵活直观的人体模型已成功应用于2D和3D HPE。虽然运动学模型具有灵活的图形表示的优点，但它在表示纹理和形状信息方面受到限制。

<a name="3.2"></a>

### 3.2 平面模型

平面模型用于表示人体的形状和外观，身体部位通常由近似人体轮廓的矩形表示，如纸板模型。主动形状模型（ASM）广泛用于通过主成分分析捕捉整个人体图形和轮廓变形。

<a name="3.3"></a>

### 3.3 体积模型

常用的3D人体模型：SMPL、DYNA（动态人体运动模型）、缝合木偶模型、弗兰肯斯坦模型、完全可训练的端到端深度学习pipeline。

<a name="4"></a>

## 4. 2D人体姿态估计

2D HPE方法从图像或视频中估计人体关键点的2D位置或空间位置。传统方法采用手工特征提取技术，将人体描述为一个棍状图形，以获得全局姿态结构。基于深度学习的方法在HPE领域取得了重大突破。

<a name="4.1"></a>

### 4.1 2D单人姿态估计

2D单人姿态估计用于定位人体关节位置。如果有多个人，则首先裁剪输入图像，以便每个裁剪的图像中只有一个人。基于深度学习的单人pipelines由两类：回归方法和身体部位检测方法。回归方法用端到端框架学习从输入图像到人体关节或人体模型参数的映射。身体部位检测方法是预测身体部位和关节的大致位置，通常由heatmap表示来监督。基于heatmap的框架现在广泛应用于2D HPE任务中。

2D单人HPE方法如下：

<div align=center><img src="../images/Deep_Learning_Based_Human_Pose_Estimation_A_Survey/2D_HPE.png" width="553" height="371"/></div>

<a name="4.1.1"></a>

#### 4.1.1 回归方法

DeepPose：AlexNet，传统方法转深度学习方法的开端。迭代误差反馈网络（IEF）：GoogLeNet，自校正模型，通过将预测误差注入输入空间来逐步改变初始解。合成姿态回归：ResNet-50，包含人体信息和姿态结构的重新参数化和基于骨骼的表示方法。文14：端到端的回归方法，使用soft-argmax函数在完全可微框架中将特征映射转换为关节坐标。

良好的特征表示对基于回归的方法至关重要，一种策略是多任务学习。通过在相关任务（如姿态估计和基于姿态的动作识别）之间共享表示信息，该模型可以更好地概括原始任务（姿态估计）。文46提出一个异构多任务框架，该框架由两个任务组成：1）构建回归器从完整图像中预测关节坐标；2）使用滑动窗口从图像块中检测身体部位。文47提出一种双源（即图像块和完整图像）深卷积神经网络（DS-CNN），用于两项任务：1）确定图像块是否包含身体关节的关节检测，2）确定关节在图像块中确切位置的关节定位。每项任务对应一个损失函数，两项任务的组合可以提高结果。文48学习一个多任务网络来联合处理来自视频序列的2D/3D姿态估计和动作识别。

<a name="4.1.2"></a>

#### 4.1.2 身体部位检测方法

身体部位检测方法旨在训练身体部位检测器来预测身体关节的位置。

将姿态估计作为热图预测问题来处理：估计K个关键点的K个热图{H1，H2，…，HK}。每个关键点热图中的像素值Hi（x，y）表示关键点位于位置（x，y）的概率。目标（或gt）热图由以gt联合位置为中心的二维高斯分布生成 。因此，通过最小化预测热图和目标热图之间的差异（例如，均方误差（MSE））来训练姿态估计网络。

与关节坐标相比，热图通过保留卷积网络的空间位置信息，为卷积网络的训练提供了更丰富的监督信息。因此，最近人们越来越有兴趣利用热图来表示关节位置，并为HPE开发有效的CNN架构。文53将基于CNN的身体部位检测器与基于部位的空间模型结合为2D HPE的统一学习框架。文55提出一种基于CNN的预测关节位置的方法。它结合关键点投票和关节概率来确定人体姿态表示。文40介绍了一种基于卷积网络的顺序框架，称为卷积姿态机（CPM），用于通过多阶段处理预测关键关节的位置（每个阶段中的卷积网络利用从先前阶段生成的2D置信图，产生身体部位位置的更加精确的预测）。文38提出一种编码器-解码器网络，在中间监督下重复自下而上和自上而下的处理。叠层沙漏（SHG）网络由pooling层和上采样层的连续组成，以捕获每个尺度的信息。之后出现很多SHG结构变体。文65设计了新的沙漏残差单元（HRU），该单元通过具有更大感受野的滤波器的侧分支扩展残差单元，捕获各种尺度的特征。文59设计一个多分支金字塔残差模块（PRM）来取代SHG中的残差单元，从而增强了深层CNN尺度的不变性。

随着GAN的出现，HPE中对其进行了探索，来生成生物学上合理的姿态配置，并区分高置信度预测和低置信度预测，从而推断出遮挡部位的潜在姿态。文67构建了一个结构感知的条件对抗网络，名为对抗PoseNet，该网络包含一个基于沙漏网络的姿态生成器和两个判别器，用于区分合理的和不合理的身体姿态。文68构建一个基于对抗性学习的网络，其中两个沙漏网络分别与判别器和生成器具有相同的结构。生成器估计每个关节的位置，判别器区分gt热图和预测热图。与基于GANs的方法不同，该方法将HPE网络作为生成器，并利用判别器提供监控，文69开发一个对抗性数据增强网络，通过将HPE网络视为判别器并使用增强网络作为生成器来执行对抗性增强，从而优化数据增强、网络训练。

除了为HPE设计高效的网络之外，还对人体结构信息进行了研究，以便为HPE网络的搭建提供更多更好的监督信息。文70为HPE设计一个端到端的CNN框架，通过整合人体各部位的空间和外观一致性，该框架能够找到难负样例。文71提出一个结构化特征级学习框架，用于推理HPE中人体关节之间的相关性，该框架捕获了更丰富的人体关节信息，提高了学习结果。文72设计一种多尺度结构感知神经网络，结合多尺度监督、多尺度特征组合、结构感知损失信息方案和关键点掩膜训练方法，以改进复杂场景中的HPE模型。文73构建一个基于沙漏的监督网络，称为深度学习的合成模型，用于描述人体各部位之间复杂而真实的关系，并学习人体中的合成模式信息（每个身体部位的方向、比例和形状信息）。文74发现并非所有部位都相互关联，因此引入了基于部位的分支网络来学习每个部位组的特定表示，而不是所有部位的共享表示。

视频序列中的人体姿态是（3D）时空信号。因此，对视频中的时空信息进行建模对于HPE非常重要。文75设计一个双分支CNN框架，将颜色和运动特征结合到帧对中，用于在HPE中构建一个表达性时空模型。文76提出一种卷积网络，该网络能够利用来自多帧的时间上下文信息，通过光流将预测的热图与相邻帧对齐。与之前基于视频的计算密集型方法不同，文60为HPE引入一种具有长短时记忆（LSTM）的循环结构，用于从不同帧捕获时间几何一致性和相关性。这种方法可以加快HPE网络的视频训练速度。文78介绍一个关键帧建议网络，用于从帧中捕获空间和时间信息，以及一个用于高效基于视频的姿态估计的人体姿态插值模块。

<a name="4.2"></a>

### 4.2 2D多人姿态估计

与单人HPE相比，多人HPE更困难、更具挑战性，因为它需要计算人数和他们的位置，以及如何为不同的人分组关键点。为了解决这些问题，多人HPE方法可以分为自顶向下和自底向上两种。自顶向下的方法使用现成的人体检测器从输入图像中获取一组框（每个框对应一个人），然后对每个人框应用单人姿态估计器来生成多人姿态。与自顶向下的方法不同，自底向上的方法首先在一张图像中定位所有身体关节，然后将它们分组到相应的目标。在自顶向下的方法中，输入图像中的人数将直接影响计算时间。自底向上方法的计算速度通常比自顶向下方法快，因为不需要分别检测每个人的姿态。

2D多人HPE方法的一般框架如下：

<div align=center><img src="../images/Deep_Learning_Based_Human_Pose_Estimation_A_Survey/multi_2D.png" width="635" height="370"/></div>

<a name="4.2.1"></a>

#### 4.2.1 自顶向下方法

自顶向下方法有两个重要部分：一个用于获取人边界框的人体检测器和一个用于预测这些边界框内关键点位置的单人姿态估计器。一些工作侧重于设计和改进HPE网络中的模块。文62在ResNet（主干网络）中添加了几个反卷积层，来构建一个简单但有效的结构，生成高分辨率表示的热图。文81提出一种新的高分辨率网络（HRNet），通过并行连接多分辨率子网络并执行重复多尺度融合来学习可靠的高分辨率表示。为了提高关键点定位的准确性，文84引入一种基于图和模型不可知的两阶段框架，称为Graph-PCNN。它由一个定位子网和一个图形姿态细化模块组成，前者用于获取粗略的关键点位置，后者用于获得精确的关键点定位表示。为了获得更精确的关键点定位，文86引入了一种残差步长网络（RSN）模块的多级网络，通过有效的层内特征融合策略学习精细的局部表示，以及姿态优化机器（PRM）模块，用于在特征中的局部和全局表示之间找到折衷。



<a name="4.2.2"></a>

#### 4.2.2 自底向上方法



<a name="4.3"></a>

### 4.3 2D HPE总结



<a name="5"></a>

## 5. 3D人体姿态估计



<a name="5.1"></a>

### 5.1 基于单目RGB图像和视频的3D HPE



<a name="5.2"></a>

### 5.2 其他来源的3D HPE



<a name="5.3"></a>

### 5.3 3D HPE总结



<a name="6"></a>

## 6. 数据集和评价指标



<a name="6.1"></a>

### 6.1 2D HPE数据集



<a name="6.2"></a>

### 6.2 2D HPE评价指标



<a name="6.3"></a>

### 6.3 2D HPE方法性能比较



<a name="6.4"></a>

### 6.4 3D HPE数据集



<a name="6.5"></a>

### 6.5 3D HPE评价指标



<a name="6.6"></a>

### 6.6 3D HPE方法性能比较





<a name="7"></a>

## 7. 应用



<a name="8"></a>

## 8. 结论和未来方向
