# Deep Learning-Based Human Pose Estimation: A Survey

------

原文链接：[点这里](https://arxiv.org/abs/2012.13392)

## 目录

- [1. 摘要](#1)
- [2. 介绍](#2)
- [3. 人体建模](#3)
  - [3.1 运动学模型](#3.1)
  - [3.2 平面模型](#3.2)
  - [3.3 体积模型](#3.3)
- [4. 2D人体姿态估计](#4)
  - [4.1 2D单人姿态估计](#4.1)
    - [4.1.1 回归方法](#4.1.1)
    - [4.1.2 身体部位检测方法](#4.1.2)
  - [4.2 2D多人姿态估计](#4.2)
    - [4.2.1 自顶向下方法](#4.2.1)
    - [4.2.2 自底向上方法](#4.2.2)
  - [4.3 2D HPE总结](#4.3)
- [5. 3D人体姿态估计](#5)
  - [5.1 基于单目RGB图像和视频的3D HPE](#5.1)
    - [5.1.1 单视图3D HPE](#5.1.1)
    - [5.1.2 多视图3D HPE](#5.1.2)
  - [5.2 其他来源的3D HPE](#5.2)
  - [5.3 3D HPE总结](#5.3)
- [6. 数据集和评价指标](#6)
  - [6.1 2D HPE数据集](#6.1)
    - [6.1.1 基于图像的数据集](#6.1.1)
    - [6.1.2 基于视频的数据集](#6.1.2)
  - [6.2 2D HPE评价指标](#6.2)
  - [6.3 2D HPE方法性能比较](#6.3)
  - [6.4 3D HPE数据集](#6.4)
  - [6.5 3D HPE评价指标](#6.5)
  - [6.6 3D HPE方法性能比较](#6.6)
- [7. 应用](#7)
- [8. 结论和未来方向](#8)

<a name="1"></a>

## 1. 摘要

人体姿态估计的目的是定位人体部位，并根据输入数据（如图像和视频）构建人体表示（如人体骨架）。其应用包括人机交互、运动分析、增强现实和虚拟现实。基于深度学习的人体姿态估计由于训练数据不足、深度模糊和遮挡而存在挑战。通过系统分析和比较，全面回顾基于深度学习的2D和3D姿势估计解决方案，还包括2D和3D人体姿态估计数据集和评价指标，性能比较。

<a name="2"></a>

## 2. 介绍

人体姿态估计（HPE）涉及从传感器捕获输入数据，特别是图像和视频，估计人体各部分的结构。HPE提供人体的几何和运动信息，已广泛应用于人机交互、运动分析、增强现实（AR）、虚拟现实（VR）、医疗保健等。此类方法已被证明在各种任务（包括图像分类、语义分割和目标检测）中优于经典的计算机视觉方法。遮挡、训练数据不足和深度模糊等对基于深度学习的HPE技术仍是需要克服的困难。基于深度学习的2D单人人体姿势估计已达到高性能，复杂场景中高度遮挡的多人HPE受到了广泛关注。对于3D HPE，获得精确的3D姿态标注比2D困难。运动捕捉系统可以在受控的实验室环境中采集3D姿态标注，但在自然环境中的应用有局限性。对于基于单目RGB图像和视频的3D HPE，主要挑战是深度模糊。在多视图设置中，视点关联是需要解决的关键问题。一些工程使用了诸如深度传感器、惯性测量单元（IMU）和射频设备等传感器，但这些方法通常不具有成本效益，并且需要专用硬件。

文11涵盖了带有RGB输入的3D HPE方法。文13回顾了2D HPE方法并分析了模型解释。文12总结了单目HPE从经典到基于深度学习的方法（到2019年），仅涵盖单目图像/视频中的2D HPE和3D单视图HPE。

综述分类如下：

<div align=center><img src="../images/Deep_Learning_Based_Human_Pose_Estimation_A_Survey/Taxonomy.png" width="813" height="166"/></div>

<a name="3"></a>

## 3. 人体建模

人体建模是HPE的一个重要方面。大多数HPE方法使用N关节刚体运动学模型。人体是具有关节和四肢的复杂实体，包含人体运动学结构和体形信息。在典型的方法中，使用基于模型的方法来描述和推断人体姿态，并渲染2D和3D姿态。人体建模通常有三种：运动学模型（用于2D/3D HPE）、平面模型（用于2D HPE）和体积模型（用于3D HPE）。

人体建模的三种类型如下：

<div align=center><img src="../images/Deep_Learning_Based_Human_Pose_Estimation_A_Survey/modeling.png" width="463" height="327"/></div>

<a name="3.1"></a>

### 3.1 运动学模型

运动学模型也称为基于骨架的模型或运动学链模型，包括一组关节位置和肢体方向，来表示人体结构，用于捕捉不同身体部位之间的关系。图形结构模型（PSM）是一种广泛使用的图形模型，也称为树结构模型。这种灵活直观的人体模型已成功应用于2D和3D HPE。虽然运动学模型具有灵活的图形表示的优点，但它在表示纹理和形状信息方面受到限制。

<a name="3.2"></a>

### 3.2 平面模型

平面模型用于表示人体的形状和外观，身体部位通常由近似人体轮廓的矩形表示，如纸板模型。主动形状模型（ASM）广泛用于通过主成分分析捕捉整个人体图形和轮廓变形。

<a name="3.3"></a>

### 3.3 体积模型

常用的3D人体模型：SMPL、DYNA（动态人体运动模型）、缝合木偶模型、弗兰肯斯坦模型、完全可训练的端到端深度学习pipeline。

<a name="4"></a>

## 4. 2D人体姿态估计

2D HPE方法从图像或视频中估计人体关键点的2D位置或空间位置。传统方法采用手工特征提取技术，将人体描述为一个棍状图形，以获得全局姿态结构。基于深度学习的方法在HPE领域取得了重大突破。

<a name="4.1"></a>

### 4.1 2D单人姿态估计

2D单人姿态估计用于定位人体关节位置。如果有多个人，则首先裁剪输入图像，以便每个裁剪的图像中只有一个人。基于深度学习的单人pipelines由两类：回归方法和身体部位检测方法。回归方法用端到端框架学习从输入图像到人体关节或人体模型参数的映射。身体部位检测方法是预测身体部位和关节的大致位置，通常由heatmap表示来监督。基于heatmap的框架现在广泛应用于2D HPE任务中。

2D单人HPE方法如下：

<div align=center><img src="../images/Deep_Learning_Based_Human_Pose_Estimation_A_Survey/2D_HPE.png" width="553" height="371"/></div>

<a name="4.1.1"></a>

#### 4.1.1 回归方法

DeepPose：AlexNet，传统方法转深度学习方法的开端。迭代误差反馈网络（IEF）：GoogLeNet，自校正模型，通过将预测误差注入输入空间来逐步改变初始解。合成姿态回归：ResNet-50，包含人体信息和姿态结构的重新参数化和基于骨骼的表示方法。文14：端到端的回归方法，使用soft-argmax函数在完全可微框架中将特征映射转换为关节坐标。

良好的特征表示对基于回归的方法至关重要，一种策略是多任务学习。通过在相关任务（如姿态估计和基于姿态的动作识别）之间共享表示信息，该模型可以更好地概括原始任务（姿态估计）。文46提出一个异构多任务框架，该框架由两个任务组成：1）构建回归器从完整图像中预测关节坐标；2）使用滑动窗口从图像块中检测身体部位。文47提出一种双源（即图像块和完整图像）深卷积神经网络（DS-CNN），用于两项任务：1）确定图像块是否包含身体关节的关节检测，2）确定关节在图像块中确切位置的关节定位。每项任务对应一个损失函数，两项任务的组合可以提高结果。文48学习一个多任务网络来联合处理来自视频序列的2D/3D姿态估计和动作识别。

<a name="4.1.2"></a>

#### 4.1.2 身体部位检测方法

身体部位检测方法旨在训练身体部位检测器来预测身体关节的位置。

将姿态估计作为热图预测问题来处理：估计K个关键点的K个热图{H1，H2，…，HK}。每个关键点热图中的像素值Hi（x，y）表示关键点位于位置（x，y）的概率。目标（或gt）热图由以gt联合位置为中心的二维高斯分布生成 。因此，通过最小化预测热图和目标热图之间的差异（例如，均方误差（MSE））来训练姿态估计网络。

与关节坐标相比，热图通过保留卷积网络的空间位置信息，为卷积网络的训练提供了更丰富的监督信息。因此，最近人们越来越有兴趣利用热图来表示关节位置，并为HPE开发有效的CNN架构。文53将基于CNN的身体部位检测器与基于部位的空间模型结合为2D HPE的统一学习框架。文55提出一种基于CNN的预测关节位置的方法。它结合关键点投票和关节概率来确定人体姿态表示。文40介绍了一种基于卷积网络的顺序框架，称为卷积姿态机（CPM），用于通过多阶段处理预测关键关节的位置（每个阶段中的卷积网络利用从先前阶段生成的2D置信图，产生身体部位位置的更加精确的预测）。文38提出一种编码器-解码器网络，在中间监督下重复自下而上和自上而下的处理。叠层沙漏（SHG）网络由pooling层和上采样层的连续组成，以捕获每个尺度的信息。之后出现很多SHG结构变体。文65设计了新的沙漏残差单元（HRU），该单元通过具有更大感受野的滤波器的侧分支扩展残差单元，捕获各种尺度的特征。文59设计一个多分支金字塔残差模块（PRM）来取代SHG中的残差单元，从而增强了深层CNN尺度的不变性。

随着GAN的出现，HPE中对其进行了探索，来生成生物学上合理的姿态配置，并区分高置信度预测和低置信度预测，从而推断出遮挡部位的潜在姿态。文67构建了一个结构感知的条件对抗网络，名为对抗PoseNet，该网络包含一个基于沙漏网络的姿态生成器和两个判别器，用于区分合理的和不合理的身体姿态。文68构建一个基于对抗性学习的网络，其中两个沙漏网络分别与判别器和生成器具有相同的结构。生成器估计每个关节的位置，判别器区分gt热图和预测热图。与基于GANs的方法不同，该方法将HPE网络作为生成器，并利用判别器提供监控，文69开发一个对抗性数据增强网络，通过将HPE网络视为判别器并使用增强网络作为生成器来执行对抗性增强，从而优化数据增强、网络训练。

除了为HPE设计高效的网络之外，还对人体结构信息进行了研究，以便为HPE网络的搭建提供更多更好的监督信息。文70为HPE设计一个端到端的CNN框架，通过整合人体各部位的空间和外观一致性，该框架能够找到难负样例。文71提出一个结构化特征级学习框架，用于推理HPE中人体关节之间的相关性，该框架捕获了更丰富的人体关节信息，提高了学习结果。文72设计一种多尺度结构感知神经网络，结合多尺度监督、多尺度特征组合、结构感知损失信息方案和关键点掩膜训练方法，以改进复杂场景中的HPE模型。文73构建一个基于沙漏的监督网络，称为深度学习的合成模型，用于描述人体各部位之间复杂而真实的关系，并学习人体中的合成模式信息（每个身体部位的方向、比例和形状信息）。文74发现并非所有部位都相互关联，因此引入了基于部位的分支网络来学习每个部位组的特定表示，而不是所有部位的共享表示。

视频序列中的人体姿态是（3D）时空信号。因此，对视频中的时空信息进行建模对于HPE非常重要。文75设计一个双分支CNN框架，将颜色和运动特征结合到帧对中，用于在HPE中构建一个表达性时空模型。文76提出一种卷积网络，该网络能够利用来自多帧的时间上下文信息，通过光流将预测的热图与相邻帧对齐。与之前基于视频的计算密集型方法不同，文60为HPE引入一种具有长短时记忆（LSTM）的循环结构，用于从不同帧捕获时间几何一致性和相关性。这种方法可以加快HPE网络的视频训练速度。文78介绍一个关键帧建议网络，用于从帧中捕获空间和时间信息，以及一个用于高效基于视频的姿态估计的人体姿态插值模块。

<a name="4.2"></a>

### 4.2 2D多人姿态估计

与单人HPE相比，多人HPE更困难、更具挑战性，因为它需要计算人数和他们的位置，以及如何为不同的人分组关键点。为了解决这些问题，多人HPE方法可以分为自顶向下和自底向上两种。自顶向下的方法使用现成的人体检测器从输入图像中获取一组框（每个框对应一个人），然后对每个人框应用单人姿态估计器来生成多人姿态。与自顶向下的方法不同，自底向上的方法首先在一张图像中定位所有身体关节，然后将它们分组到相应的目标。在自顶向下的方法中，输入图像中的人数将直接影响计算时间。自底向上方法的计算速度通常比自顶向下方法快，因为不需要分别检测每个人的姿态。

2D多人HPE方法的一般框架如下：

<div align=center><img src="../images/Deep_Learning_Based_Human_Pose_Estimation_A_Survey/multi_2D.png" width="635" height="370"/></div>

<a name="4.2.1"></a>

#### 4.2.1 自顶向下方法

自顶向下方法有两个重要部分：一个用于获取人边界框的人体检测器和一个用于预测这些边界框内关键点位置的单人姿态估计器。一些工作侧重于设计和改进HPE网络中的模块。文62在ResNet（主干网络）中添加了几个反卷积层，来构建一个简单但有效的结构，生成高分辨率表示的热图。文81提出一种新的高分辨率网络（HRNet），通过并行连接多分辨率子网络并执行重复多尺度融合来学习可靠的高分辨率表示。为了提高关键点定位的准确性，文84引入一种基于图和模型不可知的两阶段框架，称为Graph-PCNN。它由一个定位子网和一个图形姿态细化模块组成，前者用于获取粗略的关键点位置，后者用于获得精确的关键点定位表示。为了获得更精确的关键点定位，文86引入了一种残差步长网络（RSN）模块的多级网络，通过有效的层内特征融合策略学习精细的局部表示，以及姿态优化机器（PRM）模块，用于在特征中的局部和全局表示之间找到折衷。

在遮挡和截断场景下估计姿态通常发生在多人环境中，肢体重叠是不可避免的。由于遮挡或截断，人体检测器可能在自顶向下方法的第一步就会失败。因此，对遮挡或截断的鲁棒性是多人HPE方法的一个重要方面。为了实现这一目标，文88建立一个基于卷积姿态机的姿态估计器来估计关节候选。然后，他们使用整数线性规划（ILP）来解决关节与人之间的关联问题，并在严重遮挡的情况下获得人体姿态。文89设计一种新的区域多人姿态估计（RMPE）方法，用来提高HPE在复杂场景中的性能。RMPE框架由三部分组成：对称空间变换网络（用于检测不准确边界框内的单人区域）、参数姿态非极大值抑制（用于解决冗余检测问题）和姿态引导建议生成器（用于增强训练数据）。文79提出一种二阶段结构，包括一个Faster R-CNN人体检测器，为候选人体创建边界框；一个关键点估计器，使用热图偏移聚合的形式预测关键点的位置。整体方法在遮挡和杂乱场景中有良好的效果。为了缓解HPE中的遮挡问题，文90提出一种级联金字塔网络（CPN），该网络包括两部分：GlobalNet（预测眼睛或手等不可见关键点的特征金字塔网络）和RefineNet（mining loss将GlobalNet的所有级别特征与关键点相结合的网络）。结果表明，CPN在预测遮挡关键点方面有很好的性能。文91设计两个模块，Channel Shuffle Module和Spatial & Channel-wise Attention Residual Bottleneck，实现通道方面和空间信息增强，从而在遮挡场景下更好地估计多人姿态。文92开发遮挡姿态估计和校正（OPEC Net）模块，遮挡姿态数据集用来解决人群姿态估计中的遮挡问题。文93提出一个关键点对应框架，利用遮挡场景中前一帧的时间信息来恢复丢失的姿态。为了提高在稀疏标注的视频数据集中的姿态估计结果，使用自监督对网络进行训练。

<a name="4.2.2"></a>

#### 4.2.2 自底向上方法

自底向上方法有两个主要步骤：身体关节检测（提取局部特征并预测人体关节候选对象）；为个体身体分配关节候选对象（分组关节候选对象，使用部位关联策略构建最终姿态表示）。

文94提出一种基于R-CNN的快速身体部位检测器DeepCut，这是最早的两步自底向上方法之一。它首先检测所有候选身体部位，然后标记每个部位，并使用整数线性规划（ILP）将这些部位组合到最终姿态。但DeepCut模型的计算成本很高。文95引入DeeperCut，通过将更强大的身体部位检测器、更好的增量优化策略和图像条件下的成对项应用于身体部位分组来改进DeepCut，提高性能和速度。文17构建一个名为OpenPose的检测器，该检测器使用卷积姿态机（CPMs）通过热图和Part Affinity Fields（PAFs，一组二维向量场，带有编码肢体位置和方向的向量图）预测关键点坐标，用来将关键点与每个人关联。OpenPose大大加快了自底向上的多人HPE速度。基于OpenPose框架，文104改进了OpenPose结构，通过添加冗余边来增加PAFs中关节之间的连接，并获得了比基线方法更好的性能。尽管基于OpenPose的方法在高分辨率图像上取得了令人印象深刻的效果，但在低分辨率图像和遮挡情况下，它们的性能较差。为了解决这个问题，文100提出PifPaf方法，该方法使用部位强度场（PIF）来预测身体部位的位置，并使用部位关联场（PAF）来表示关节关联。在低分辨率和遮挡场景下，该方法优于以往基于OpenPose的方法。受OpenPose和堆叠沙漏结构的启发，文97引入单级深度网络，用来同时获得姿态检测和组分配。之后文102提出一种新的可微分层图分组（HGG）方法来学习人体部位分组。文103在文97和文81的基础上提出一种简单的HRNet扩展，称为高分辨率网络（HigherRnet），它对HRNet生成的高分辨率热图去卷积，用来解决自底向上的多人姿态估计中的尺度变化挑战。

自底向上的HPE方法也采用了多任务结构。文105引入PersonLab，将姿态估计模块和人物分割模块结合起来，用于关键点检测和关联。PersonLab由短期偏移（细化热图）、中期偏移（预测关键点）和长期偏移（将关键点分组到实例中）组成。文106提出一个多任务学习模型，该模型带有一个姿态残差网络MultiPoseNet，可以同时执行关键点预测、人体检测和语义分割任务。

<a name="4.3"></a>

### 4.3 2D HPE总结

2D单人HPE：DeepPose，堆叠沙漏网络；2D多人HPE：AlphaPose，OpenPose。

回归和身体部位检测方法在2D单人HPE中有各自的优势和局限性。回归方法可以通过端到端的框架学习从输入图像到关键点坐标的非线性映射，这提供了一种快速的学习模式和亚像素级的预测精度。但由于高度非线性的问题，通常给出的是次优解。人体部位检测方法尤其是基于热图的框架，在2D HPE中得到了更广泛的应用，因为（1）热图中每个像素的概率预测可以提高关键点定位的准确性；（2）热图通过保存空间位置信息提供更丰富的监控信息。但预测关键点的精度取决于热图的分辨率。使用高分辨率热图时，计算成本和内存占用显著增加。

对于2D多人HPE的自顶向下和自底向上方法，很难确定哪种方法更好，因为这两种方法在近期研究中都被广泛使用，各有优缺点。一方面，自顶向下的方法能产生更好的结果，因为它首先使用检测方法从图像中检测每个个体，然后使用基于单个个体的方法预测关键点的位置。在这种情况下，随着背景基本上被移除，每个检测到的人区域内的关键点热图估计变得容易。另一方面，自底向上的方法通常比自顶向下的方法更快，因为它直接检测所有关键点，并使用关键点关联策略（如亲和力链接、关联嵌入和逐像素关键点回归）将其分组为单独的姿态。

2D HPE有几个挑战需要在未来的研究中进一步解决。首先是在显著遮挡下可靠地检测个体。对于自顶向下的方法，人体检测器可能无法识别大部分重叠人体的边界。对于自底向上方法，关键点关联的难度更大。

第二是计算效率。尽管像OpenPose这样的一些方法可以在具有中等算力的特殊硬件上实现近实时处理（如在配备Nvidia GTX 1080 Ti GPU的机器上实现22 FPS），但在资源受限的设备上实现网络仍然很困难。现实世界的应用（如在线辅导、游戏、AR和VR）需要在商业设备上使用更高效的HPE方法，从而为用户带来更好的交互体验。

第三是罕见姿态数据有限。尽管2D HPE当前数据集大小对于正常姿态估计（例如站立、行走、跑步）来说足够大（如COCO数据集），但这些数据集对于异常姿态（例如坠落）的训练数据有限。数据不平衡可能会导致模型偏差，导致这些姿态的表现不佳。有效的数据生成或增强技术很有用，用来生成额外的姿态数据，用于训练更鲁棒的模型。

<a name="5"></a>

## 5. 3D人体姿态估计

3D HPE是一种能够预测人体关节在3D空间中位置的技术，近年来受到了广泛关注，因为它可以提供与人体相关的大量3D结构信息。有许多应用，如3D电影和动画行业、虚拟现实和在线3D动作预测等。尽管最近2D HPE取得了显著进步，3D HPE仍然是一项具有挑战性的任务。现有的大多数研究工作都是针对单目图像或视频的3D HPE，由于3D到2D的投影丢失了一维，因此是一个不适定的逆问题。当能够获得多视点或者部署了IMU和LiDAR等其他传感器时，3D HPE则是一个采用信息融合技术的适定问题。另一个限制是深度学习模型需要大量数据，并且对数据收集环境敏感。与2D人体数据集不同，在2D人体数据集中，可以轻松获得精确的2D姿态标注，但收集精确的3D姿态标注非常耗时，手动标记也不实用。此外，数据集通常是从室内环境中收集的，并带有选定的日常动作。近期工作验证了使用有偏数据集训练的模型在交叉数据集进行推理时泛化能力差的问题。

<a name="5.1"></a>

### 5.1 基于单目RGB图像和视频的3D HPE

单目相机是在2D和3D场景中应用最广泛的HPE传感器。基于单目图像和视频的深度学习2D HPE的最新进展使研究人员能够将他们的工作扩展到3D HPE。具体来说，基于深度学习的3D HPE方法分为两大类：单视图3D HPE和多视图3D HPE。

<a name="5.1.1"></a>

#### 5.1.1 单视图3D HPE

从单目图像和视频的单视图重建3D人体姿态是一项非常重要的任务，它会受到自身遮挡和其他目标遮挡、深度模糊、训练数据不足的影响。这是一个严重的不适定问题，因为不同的3D人体姿态可以投影到类似的2D姿态投影。此外，对于基于2D关节的方法，2D身体关节的微小定位误差可能会导致3D空间中的较大姿态失真。与单人情况相比，多人情况更加复杂。

##### A 单人3D HPE

单人3D HPE框架：

<div align=center><img src="../images/Deep_Learning_Based_Human_Pose_Estimation_A_Survey/single_person_3D.png" width="546" height="381"/></div>

根据单人3D HPE方法是否使用人体模型来估计3D人体姿态，将其分为Model-free和model-based两类。

1）Model-free方法

Model-free方法不使用人体模型来重建3D人体表示。这些方法可进一步分为两类：（1）直接估计方法；（2）2D到3D扩展方法。

直接估计：直接估计方法从2D图像推断3D人体姿态，不需要中间估计2D姿态表示。文114提出一种深度学习方法，采用浅层网络，通过同步滑动窗口和姿态坐标回归训练身体部位检测。文115提出一种后续方法，其中图像3D姿态对被用作网络输入。分数网络可以将高分分配给正确的图像3D姿态对，将低分分配给其他姿态对。然而，这些方法效率很低，因为它们需要多个前向网络推理。文43提出一种结构感知回归方法。没有使用基于关节的表示法，而是采用更稳定的基于骨骼的表示法。通过利用基于骨骼表示的3D骨骼结构定义成分损失，骨骼表示由骨骼之间的远程交互进行编码。文116通过学习3D姿态到高维潜在空间的映射，对关节之间的结构依赖进行编码。学到的高维姿态表示可以强化3D姿态的结构性约束。文117、118引入了体积表示法，将高度非线性的3D坐标回归问题转化为离散空间中可管理的形式。体积中每个关节的体素可能性由卷积网络预测。人体关节的顺序深度关系被用来缓解对精确3D gt姿态的需求。

2D到3D扩展：受2D HPE的启发，2D到3D扩展方法（由中间估计的2D人体姿态推断3D人体姿态）已成为3D HPE流行的解决方案。得益于SOTA2D姿态检测器的出色性能，2D到3D扩展方法通常优于直接估计方法。在第一阶段中，使用现成的2D HPE模型来估计2D姿态，然后在第二阶段中使用2D到3D扩展来获得3D姿态。文120从库中部署一个预测的2D姿态和3D姿态最近邻匹配。然而，如果3D姿态与给定2D姿态的图像没有条件独立，3D HPE可能会失败。文121提出一种简单但有效的全连通残差网络，以基于2D关节位置回归3D关节位置。尽管当时取得了最先进的结果，但由于过度依赖2D姿态检测器而导致重建模糊，该方法可能会失败。文122和文123使用2D热图而不是2D姿态作为估算3D姿态的中间表示。文124通过距离矩阵回归推断出3D人体姿态，其中2D和3D身体关节的距离被编码为两个欧几里德距离矩阵（EDMs）。EDM对平面内图像的旋转和平移保持不变，并且在应用归一化操作时具有缩放不变性。文125开发一种成对排序卷积神经网络（PRCNN），用于预测成对人类关节的深度排序。然后，使用由粗到精的姿态估计器从2D关节和深度排序矩阵回归3D姿态。文126、127、128首先生成多种不同的3D姿态假设，然后应用排序网络选择最佳3D姿态。

鉴于人体姿态可以表示为一个图，其中关节是节点，骨骼是边缘，因此图卷积网络（GCN）已被应用于2D到3D姿态扩展问题，并表现出良好的性能。文131提出Pose2Mesh，是一种基于GCN的方法，用于从PoseNet中细化中间3D姿态。有了GCN，MeshNet就可以使用由网格拓扑构造的图形来回归网格顶点的3D坐标。文129提出一个通用框架，名为局部连接网络（LCN），利用全连接网络和GCN来编码局部关节邻域之间的关系。LCN可以克服GCN的局限性，即权重共享方案有损姿态估计模型的表示能力，并且结构矩阵缺乏灵活性，无法支持定制的节点依赖。文130也解决了GCN中所有节点卷积滤波器共享权重矩阵的局限性。为了研究语义信息和语义关系，提出了语义GCN。语义图卷积（SemGConv）操作用于学习边缘的通道权重。由于SemGConv和非局部层是交错的，所以节点之间的局部和全局关系都被捕获。

<a name="5.1.2"></a>

#### 5.1.2 多视图3D HPE



<a name="5.2"></a>

### 5.2 其他来源的3D HPE



<a name="5.3"></a>

### 5.3 3D HPE总结



<a name="6"></a>

## 6. 数据集和评价指标

数据集对HPE很重要并且是必要的，但收集全面、通用的数据集很有挑战。

<a name="6.1"></a>

### 6.1 2D HPE数据集

在深度学习进入人体姿态估计之前，有很多2D人体姿势数据集。这些数据集有两种类型：（1）上半身姿态数据集，包括Buffy Stickmen、ETHZ PASCAL Stickmen、We Are Family、Video pose 2和Sync. Activities；（2）全身姿势数据集，包括PASCAL Person
Layout、Sport和UIUC people。然而，最近只有少数工作使用这些2D HPE数据集，它们有许多局限性，如缺乏多样的物体运动、图片数量少。

2D HPE数据集介绍：

<div align=center><img src="../images/Deep_Learning_Based_Human_Pose_Estimation_A_Survey/2D_HPE_datasets.png" width="638" height="381"/></div>

<a name="6.1.1"></a>

#### 6.1.1 基于图像的数据集

Frames Labeled In Cinema (FLIC)数据集：早期基于图像的2D HPE数据集之一，包含5003张图像（好莱坞电影中收集）。大约4000张用做训练集，其余用做测试集。使用Poselets的身体部位检测器，从电影中获取的完整帧集称为FLIC完整数据集。它是原始FLIC数据集的超集，包含20928个遮挡的非正样本。文53引入一个新的基于FLIC的数据集FLIC plus，该数据集删除了与FLIC测试集相同场景的所有图像。

<a name="6.1.2"></a>

#### 6.1.2 基于视频的数据集



<a name="6.2"></a>

### 6.2 2D HPE评价指标



<a name="6.3"></a>

### 6.3 2D HPE方法性能比较



<a name="6.4"></a>

### 6.4 3D HPE数据集



<a name="6.5"></a>

### 6.5 3D HPE评价指标



<a name="6.6"></a>

### 6.6 3D HPE方法性能比较





<a name="7"></a>

## 7. 应用



<a name="8"></a>

## 8. 结论和未来方向
